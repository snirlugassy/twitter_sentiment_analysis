{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from models.gru import SentimentGRU_A\n",
    "from models.transformer import SentimentTransformerEncoder_C\n",
    "\n",
    "from dataset import SentimentAnalysisDataset, LABEL_MAP\n",
    "from test import run_test\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "RESULTS_DIR = 'results'\n",
    "\n",
    "MODELS = {\n",
    "    'a': SentimentGRU_A,\n",
    "    'b': None,\n",
    "    'c': SentimentTransformerEncoder_C\n",
    "}\n",
    "\n",
    "data_path = 'data'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentGRU_A(\n",
       "  (gru): GRU(100, 128, num_layers=4, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a = SentimentGRU_A(100)\n",
    "model_a.load_state_dict(torch.load('models/A_06_05_13_26.state'))\n",
    "model_a.to(device)\n",
    "model_a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentTransformerEncoder_C(\n",
       "  (tranformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.33, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=50, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b = SentimentTransformerEncoder_C(100)\n",
    "model_b.load_state_dict(torch.load('models/C_06_05_13_25.state'))\n",
    "model_b.to(device)\n",
    "model_b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading word embeddings\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SentimentAnalysisDataset(os.path.join(data_path, 'trainEmotions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading word embeddings\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SentimentAnalysisDataset(os.path.join(data_path, 'testEmotions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ensemble_predict(models, dataset, device):\n",
    "    y_true = []\n",
    "    y_predict = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tokens, label in dataset:\n",
    "            \n",
    "            tokens = tokens.to(device).float()\n",
    "            label = label.to(device)\n",
    "\n",
    "            y_true.append(int(label.argmax()))\n",
    "\n",
    "            if tokens.squeeze().dim() == 0 or len(tokens.squeeze()) == 0:\n",
    "                # Predict neutral if no token after processing \n",
    "                # e.g., only stopwords in the original text\n",
    "                y_predict.append(int(LABEL_MAP['neutral']))\n",
    "                continue\n",
    "\n",
    "            # Forward pass\n",
    "            y_predict.append([model(tokens) for model in models])\n",
    "            # output = model(tokens)\n",
    "            # if output.dim() != 1 or output.shape[0] != 3:\n",
    "            #     print(output.shape, tokens.shape, label.shape)\n",
    "            # assert output.dim() == 1 and output.shape[0] == 3\n",
    "            # y_predict.append(int(torch.softmax(output, dim=0).argmax()))\n",
    "\n",
    "    return y_true, y_predict\n",
    "    # return accuracy_score(y_true, y_predict), precision_score(y_true, y_predict), recall_score(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_predict = model_ensemble_predict([model_a, model_b], test_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach A\n",
    "\n",
    "Average the prediction with equal weight to each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5189166838949762\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "for outputs in y_predict:\n",
    "    try:\n",
    "        _y = torch.softmax(sum(outputs) / 2, dim=0)\n",
    "    except:\n",
    "        _y = torch.Tensor([0,1,0])\n",
    "    y.append(int(_y.argmax(dim=0)))\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_true, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5375232582179037\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "for outputs in y_predict:\n",
    "    if isinstance(outputs, int):\n",
    "        outputs = [torch.Tensor([0,1,0]), torch.Tensor([0,1,0])]\n",
    "    \n",
    "    _y = [torch.softmax(x, dim=0) for x in outputs]\n",
    "    confidence = [max(x) for x in _y]\n",
    "    most_confident = confidence.index(max(confidence))\n",
    "\n",
    "    _y = _y[most_confident]\n",
    "    y.append(int(_y.argmax(dim=0)))\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_true, y))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d538358a4a844c2698117f72ddbeea822b864d784b5f9260aa8445549be4a00"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
