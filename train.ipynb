{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import SentimentAnalysisDataset\n",
    "import pickle\n",
    "from model import SentimentLSTM\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from dataset import SentimentAnalysisDataset\n",
    "\n",
    "def load_embeddings(pretrained_file):\n",
    "    embeddings = {}\n",
    "    with open(pretrained_file,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embeddings[word] = np.array(split_line[1:], dtype=np.float64)\n",
    "    print(f\"{len(embeddings)} words loaded!\")\n",
    "    return embeddings\n",
    "\n",
    "emb = load_embeddings('glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = len(emb['the'])\n",
    "emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
       "         -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
       "          0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
       "          0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
       "          0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
       "         -0.7179, -0.4153,  0.2034, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
       "         -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9978, -0.8048, -3.0243,\n",
       "          0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
       "          1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
       "         -0.3080, -0.4163,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
       "          0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
       "          0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
       "         -0.5203, -0.1459,  0.8278,  0.2706], dtype=torch.float64),\n",
       " tensor([ 0.2309,  0.2828,  0.6318, -0.5941, -0.5860,  0.6325,  0.2440, -0.1411,\n",
       "          0.0608, -0.7898, -0.2910,  0.1429,  0.7227,  0.2043,  0.1407,  0.9876,\n",
       "          0.5253,  0.0975,  0.8822,  0.5122,  0.4020,  0.2117, -0.0131, -0.7162,\n",
       "          0.5539,  1.1452, -0.8804, -0.5022, -0.2281,  0.0239,  0.1072,  0.0837,\n",
       "          0.5502,  0.5848,  0.7582,  0.4571, -0.2800,  0.2522,  0.6896, -0.6097,\n",
       "          0.1958,  0.0442, -0.3114, -0.6883, -0.2272,  0.4618, -0.7716,  0.1021,\n",
       "          0.5564,  0.0674, -0.5721,  0.2374,  0.4717,  0.8276, -0.2926, -1.3422,\n",
       "         -0.0993,  0.2814,  0.4160,  0.1058,  0.6220,  0.8950, -0.2345,  0.5135,\n",
       "          0.9938,  1.1846, -0.1636,  0.2065,  0.7385,  0.2406, -0.9647,  0.1348,\n",
       "         -0.0072,  0.3302, -0.1236,  0.2719, -0.4095,  0.0219, -0.6069,  0.4076,\n",
       "          0.1957, -0.4180,  0.1864, -0.0327, -0.7857, -0.1385,  0.0440, -0.0844,\n",
       "          0.0491,  0.2410,  0.4527, -0.1868,  0.4618,  0.0891, -0.1819, -0.0152,\n",
       "         -0.7368, -0.1453,  0.1510, -0.7149], dtype=torch.float64),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for t in ['the', 'cat', 'kwjelrk']:\n",
    "    if t in emb:\n",
    "        tokens.append(torch.from_numpy(emb[t]))\n",
    "    else:\n",
    "        tokens.append(torch.zeros(emb_dim))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.stack(tokens)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snirlugassy/Projects/sentiment_analysis/dataset.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_croot-udngs7fm/pytorch_1648016055234/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  for t in self.df.iloc[idx]['clean']:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SentimentAnalysisDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/trainEmotions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, emb, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m tokens, emotion \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m tokens\u001b[38;5;241m.\u001b[39mshape, emotion\n",
      "File \u001b[0;32m~/Projects/sentiment_analysis/dataset.py:45\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m     if t in self.embedding:\n\u001b[1;32m     44\u001b[0m         tokens.append(torch.from_numpy(self.embedding[t]))\n\u001b[0;32m---> 45\u001b[0m     else:\n\u001b[1;32m     46\u001b[0m         tokens.append(torch.zeros(self.embedding_dim))\n\u001b[1;32m     47\u001b[0m tokens = torch.stack(tokens)\n",
      "File \u001b[0;32m~/Projects/sentiment_analysis/dataset.py:42\u001b[0m, in \u001b[0;36mget_tokens_vec\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_vecs[idx]\n\u001b[1;32m     41\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding:\n\u001b[1;32m     44\u001b[0m         tokens\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding[t]))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "dataset = SentimentAnalysisDataset('data/trainEmotions.csv', emb, embedding_dim=100)\n",
    "tokens, emotion = dataset[0]\n",
    "tokens.shape, emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SentimentAnalysisDataset('data/trainEmotions.csv', vocab)\n",
    "tokens, emotion = dataset[0]\n",
    "\n",
    "model = SentimentLSTM(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 300])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.embedding(tokens)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 400])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,_ = model.lstm(model.embedding(tokens))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 3]),\n",
       " tensor([[-0.1283,  0.0213,  0.0023],\n",
       "         [-0.1297,  0.0250,  0.0052],\n",
       "         [-0.1271,  0.0224,  0.0036],\n",
       "         [-0.1268,  0.0215,  0.0012],\n",
       "         [-0.1231,  0.0217,  0.0051],\n",
       "         [-0.1247,  0.0250,  0.0030],\n",
       "         [-0.1209,  0.0241,  0.0016],\n",
       "         [-0.1177,  0.0232,  0.0018],\n",
       "         [-0.1152,  0.0215,  0.0032],\n",
       "         [-0.1181,  0.0205,  0.0060],\n",
       "         [-0.1237,  0.0193,  0.0065]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.fc(x)\n",
    "output.shape, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1].shape, emotion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1917, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(output[-1].view(1,-1), emotion.view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([emotion])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d538358a4a844c2698117f72ddbeea822b864d784b5f9260aa8445549be4a00"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
